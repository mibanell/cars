{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing with tensorflow pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/autos.csv', encoding='cp1252', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.3, random_state=666)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=666)\n",
    "\n",
    "# drop Price outlier\n",
    "price_desc = train.price.describe()\n",
    "max_price_outlier = (price_desc['75%'] - price_desc['25%'])*3 + price_desc['75%']\n",
    "train = train.loc[(train.price < max_price_outlier) & (train.price > 0),]\n",
    "val = val.loc[(val.price < max_price_outlier) & (val.price > 0),]\n",
    "# filter year\n",
    "train = train.loc[(train.yearOfRegistration >= 1864) & (train.yearOfRegistration <= 2017)]\n",
    "val = val.loc[(val.price < 80000000) & (val.price > 0),]\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "# save data\n",
    "train.to_csv('data/train.csv', sep=',', index=False)\n",
    "val.to_csv('data/val.csv', sep=',', index=False)\n",
    "test.to_csv('data/test.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NAs\n",
    "\n",
    "## model, vehicleType, fuelType NAs with \"NA\"\n",
    "train.model = train.model.fillna('_NA')\n",
    "train.vehicleType = train.vehicleType.fillna('_NA')\n",
    "train.fuelType = train.fuelType.fillna('_NA')\n",
    "\n",
    "## fill notRepairedDamage NAs with 'nein'\n",
    "train.notRepairedDamage = train.notRepairedDamage.fillna('nein')\n",
    "\n",
    "## fill gearbox NAs with most frequent gearbox for model-brand\n",
    "gearbox_na = train.copy()\\\n",
    "    .loc[train.gearbox.isna() != True,['gearbox','model','brand']]\\\n",
    "    .groupby(['model','brand'], as_index=False)\\\n",
    "    .agg(lambda x:x.value_counts().index[0])\n",
    "## fill powerps NAs with mean power for model-brand\n",
    "powerPS_na = train.copy()\\\n",
    "    .loc[train.powerPS > 0,['powerPS','model','brand']]\\\n",
    "    .groupby(['model','brand'], as_index=False)\\\n",
    "    .mean()\n",
    "\n",
    "gearbox_powerps_na = pd.merge(gearbox_na, powerPS_na, on=['model','brand'], how='outer')\n",
    "\n",
    "## Save na_encoding\n",
    "gearbox_powerps_na.to_csv('data/gearbox_powerps_na.csv', sep=',', index=False)\n",
    "\n",
    "train = pd.merge(train, gearbox_powerps_na, on=['model','brand'], suffixes = ('','_na'), how='left')\n",
    "\n",
    "train.loc[train.gearbox.isna(),'gearbox'] = train.loc[train.gearbox.isna(),'gearbox_na']\n",
    "train.loc[train.powerPS.isna(),'powerPS'] = train.loc[train.powerPS.isna(),'powerPS_na']\n",
    "\n",
    "## case when for a model-brand there is no info of any gearbox\n",
    "train.loc[train.gearbox.isna(),'gearbox'] = train.gearbox.mode().values\n",
    "\n",
    "## case when for a model-brand there is no info of any powerPS\n",
    "train.loc[train.powerPS.isna(),'powerPS'] = train.powerPS.mean()\n",
    "\n",
    "train = train.drop(['gearbox_na', 'powerPS_na'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dateCrawled            0\n",
       "name                   0\n",
       "seller                 0\n",
       "offerType              0\n",
       "price                  0\n",
       "abtest                 0\n",
       "vehicleType            0\n",
       "yearOfRegistration     0\n",
       "gearbox                0\n",
       "powerPS                0\n",
       "model                  0\n",
       "kilometer              0\n",
       "monthOfRegistration    0\n",
       "fuelType               0\n",
       "brand                  0\n",
       "notRepairedDamage      0\n",
       "dateCreated            0\n",
       "nrOfPictures           0\n",
       "postalCode             0\n",
       "lastSeen               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check NA\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform yearOfRegistration feature\n",
    "## Data is from 2017\n",
    "train.yearOfRegistration = 2017 - train.yearOfRegistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features\n",
    "numerical_features = ['yearOfRegistration', 'powerPS', 'kilometer']\n",
    "\n",
    "numerical_features_normalization = pd.DataFrame({\n",
    "    'feature': numerical_features,\n",
    "    'mean': [np.mean(train[x]) for x in numerical_features],\n",
    "    'std': [np.std(train[x]) for x in numerical_features]\n",
    "})\n",
    "\n",
    "numerical_features_normalization\n",
    "\n",
    "# save normalization parameters\n",
    "numerical_features_normalization.to_csv('data/numerical_features_normalization.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yearOfRegistration</td>\n",
       "      <td>13.822326</td>\n",
       "      <td>7.665979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>powerPS</td>\n",
       "      <td>115.608013</td>\n",
       "      <td>190.277829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kilometer</td>\n",
       "      <td>125670.457330</td>\n",
       "      <td>40040.277549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature           mean           std\n",
       "0  yearOfRegistration      13.822326      7.665979\n",
       "1             powerPS     115.608013    190.277829\n",
       "2           kilometer  125670.457330  40040.277549"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, target_name, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    targets = dataframe.pop(target_name)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), targets))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "        ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size, target_name='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_numerical_feature(name):\n",
    "    \n",
    "    numerical_feature = tf.feature_column.numeric_column(name)\n",
    "    \n",
    "    return numerical_feature\n",
    "    \n",
    "def set_one_hot_feature(name, data):\n",
    "    one_hot_feature = tf.feature_column.categorical_column_with_vocabulary_list(name, data[name].unique().tolist())\n",
    "    one_hot_feature = tf.feature_column.indicator_column(one_hot_feature)\n",
    "    \n",
    "    return one_hot_feature\n",
    "\n",
    "def set_embedding_feature(name, data, dims):\n",
    "    embedding_feature = tf.feature_column.categorical_column_with_vocabulary_list(name, data[name].unique().tolist())\n",
    "    embedding_feature = tf.feature_column.embedding_column(embedding_feature, dimension=dims)\n",
    "    \n",
    "    return embedding_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_columns(data, dataset):\n",
    "    \n",
    "    feature_columns = []\n",
    "\n",
    "    # numeric cols\n",
    "    for header in ['yearOfRegistration', 'powerPS', 'kilometer']:\n",
    "        feature_columns.append(set_numerical_feature(header))\n",
    "\n",
    "    feature_columns.append(set_one_hot_feature('abtest', data))\n",
    "    \n",
    "    feature_columns.append(set_embedding_feature('vehicleType', data, 4))\n",
    "    \n",
    "    feature_columns.append(set_one_hot_feature('gearbox', data))\n",
    "    \n",
    "    feature_columns.append(set_embedding_feature('model', data, 8))\n",
    "    \n",
    "    feature_columns.append(set_one_hot_feature('fuelType', data))\n",
    "    \n",
    "    feature_columns.append(set_embedding_feature('brand', data, 6))\n",
    "    \n",
    "    feature_columns.append(set_one_hot_feature('notRepairedDamage', data))\n",
    "    \n",
    "    feature_columns.append(set_embedding_feature('postalCode', data, 10))\n",
    "    \n",
    "\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "    \n",
    "    return(feature_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_layer = feature_columns(train, train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fn(path, norm_params, na_encoding):\n",
    "    \n",
    "    # Load files as pandas df\n",
    "    data = pd.read_csv(path, index_col=None)\n",
    "    norm_params = pd.read_csv(norm_params, encoding='cp1252', index_col=None)\n",
    "    na_encoding = pd.read_csv(na_encoding, encoding='cp1252', index_col=None)\n",
    "    \n",
    "    # Fill NAs model, vehicle and fuel with 'NA'\n",
    "    data.model = data.model.fillna('NA')\n",
    "    data.vehicleType = data.vehicleType.fillna('NA')\n",
    "    data.fuelType = data.fuelType.fillna('NA')\n",
    "    \n",
    "    ## fill notRepairedDamage NAs with 'nein'\n",
    "    data.notRepairedDamage = data.notRepairedDamage.fillna('nein')\n",
    "    \n",
    "    ## fill gearbox and powerPS NAs with na_encoding\n",
    "    data = pd.merge(data, na_encoding, on=['model','brand'], suffixes = ('','_na'), how='left')\n",
    "    data.loc[data.gearbox.isna(),'gearbox'] = data.loc[data.gearbox.isna(),'gearbox_na']\n",
    "    data.loc[data.powerPS.isna(),'powerPS'] = data.loc[data.powerPS.isna(),'powerPS_na']\n",
    "    data = data.drop(['gearbox_na', 'powerPS_na'], axis=1)\n",
    "    \n",
    "    ## Drop rows where all rows for a model-brand combination are NA\n",
    "    #data = data.loc[(data.gearbox.isna() == False) & (data.powerPS.isna() == False),]\n",
    "    \n",
    "    \n",
    "    # Numerical features normalization\n",
    "    for num_col in ['yearOfRegistration', 'powerPS', 'kilometer']:\n",
    "        if num_col == 'yearOfRegistration':\n",
    "            data[num_col] = 2017 - data[num_col] # feature as car age, we assume we are in 2017.\n",
    "        data[num_col] = (data[num_col] - norm_params.loc[norm_params.feature == num_col,'mean'].values)/norm_params.loc[norm_params.feature == num_col,'std'].values\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = preprocessing_fn(path='data/train.csv', norm_params='data/numerical_features_normalization.csv', na_encoding='data/gearbox_powerps_na.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2851"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.gearbox.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carskernel",
   "language": "python",
   "name": "carskernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
