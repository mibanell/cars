{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model arquitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras, dtypes\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import feature_column\n",
    "from preprocess_tf import preprocessing_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, target_name, shuffle=True, batch_size=100):\n",
    "    dataframe = dataframe.copy()\n",
    "    targets = dataframe.pop(target_name)\n",
    "    ds = Dataset.from_tensor_slices((dict(dataframe), targets))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "        ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_numerical_feature(name):\n",
    "    \n",
    "    numerical_feature = feature_column.numeric_column(name, dtype=dtypes.float64)\n",
    "    \n",
    "    return numerical_feature\n",
    "    \n",
    "def set_one_hot_feature(name, data):\n",
    "    one_hot_feature = feature_column.categorical_column_with_vocabulary_list(name, data[name].unique().tolist())\n",
    "    one_hot_feature = feature_column.indicator_column(one_hot_feature)\n",
    "    \n",
    "    return one_hot_feature\n",
    "\n",
    "def set_embedding_feature(name, data, dims):\n",
    "    embedding_feature = feature_column.categorical_column_with_vocabulary_list(name, data[name].unique().tolist())\n",
    "    embedding_feature = feature_column.embedding_column(embedding_feature, dimension=dims)\n",
    "    \n",
    "    return embedding_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_columns(data, dataset):\n",
    "    \n",
    "    feature_columns = []\n",
    "\n",
    "    # numeric cols\n",
    "    for header in ['yearOfRegistration', 'powerPS', 'kilometer']:\n",
    "        feature_columns.append(set_numerical_feature(header))\n",
    "\n",
    "    feature_columns.append(set_one_hot_feature('abtest', data))\n",
    "    \n",
    "    feature_columns.append(set_embedding_feature('vehicleType', data, 4))\n",
    "    \n",
    "    feature_columns.append(set_one_hot_feature('gearbox', data))\n",
    "    \n",
    "    feature_columns.append(set_embedding_feature('model', data, 8))\n",
    "    \n",
    "    feature_columns.append(set_one_hot_feature('fuelType', data))\n",
    "    \n",
    "    feature_columns.append(set_embedding_feature('brand', data, 6))\n",
    "    \n",
    "    feature_columns.append(set_one_hot_feature('notRepairedDamage', data))\n",
    "    \n",
    "    feature_columns.append(set_embedding_feature('postalCode', data, 10))\n",
    "    \n",
    "\n",
    "    feature_layer = layers.DenseFeatures(feature_columns)\n",
    "    \n",
    "    return(feature_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocessing_fn(path='data/train.csv', na_encoding='data/gearbox_powerps_na.csv', norm_params='data/numerical_features_normalization.csv')\n",
    "val = preprocessing_fn(path='data/val.csv', na_encoding='data/gearbox_powerps_na.csv', norm_params='data/numerical_features_normalization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dateCrawled             object\n",
       "name                    object\n",
       "seller                  object\n",
       "offerType               object\n",
       "price                    int64\n",
       "abtest                  object\n",
       "vehicleType             object\n",
       "yearOfRegistration     float32\n",
       "gearbox                 object\n",
       "powerPS                float32\n",
       "model                   object\n",
       "kilometer              float32\n",
       "monthOfRegistration      int64\n",
       "fuelType                object\n",
       "brand                   object\n",
       "notRepairedDamage       object\n",
       "dateCreated             object\n",
       "nrOfPictures             int64\n",
       "postalCode               int64\n",
       "lastSeen                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = df_to_dataset(dataframe=train, target_name='price', shuffle=True, batch_size=1000)\n",
    "val_ds = df_to_dataset(dataframe=val, target_name='price', shuffle=True, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = feature_columns(train, train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = layers.Dense(100, activation='relu')(feature_layer)\n",
    "\n",
    "# x = layers.Dense(100, activation='relu')(x)\n",
    "\n",
    "# output = layers.Dense(1, activation='relu')(x)\n",
    "\n",
    "# model = keras.Model(inputs=feature_layer, outputs=output, name=\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 6889.6401 - val_loss: 8221.8330\n",
      "Epoch 2/15\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 5153.7466 - val_loss: 5610.9897\n",
      "Epoch 3/15\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 3012.7102 - val_loss: 5059.6162\n",
      "Epoch 4/15\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2683.3699 - val_loss: 4940.8911\n",
      "Epoch 5/15\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2637.4827 - val_loss: 6082.4800\n",
      "Epoch 6/15\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2558.6370 - val_loss: 4822.6445\n",
      "Epoch 7/15\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 2486.1973 - val_loss: 5315.5005\n",
      "Epoch 8/15\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2440.3093 - val_loss: 5651.6235\n",
      "Epoch 9/15\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2421.1458 - val_loss: 4698.5859\n",
      "Epoch 10/15\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 2414.2988 - val_loss: 5229.4351\n",
      "Epoch 11/15\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 2387.8699 - val_loss: 4687.7461\n",
      "Epoch 12/15\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 2365.5396 - val_loss: 4811.3979\n",
      "Epoch 13/15\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 2365.2703 - val_loss: 4702.1665\n",
      "Epoch 14/15\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 2347.3145 - val_loss: 4706.5464\n",
      "Epoch 15/15\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 2335.5237 - val_loss: 4722.2373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27c19a106a0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_rate = 0.5\n",
    "lr = 0.001\n",
    "hu = 150\n",
    "\n",
    "model = keras.Sequential([\n",
    "    feature_layer,\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(60, activation='relu'),\n",
    "    #layers.Dropout(rate=dp_rate),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    #layers.Dropout(rate=dp_rate),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    #layers.Dropout(rate=dp_rate),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(240, activation='relu'),\n",
    "    #layers.Dropout(rate=dp_rate),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(240, activation='relu'),\n",
    "    #layers.Dropout(rate=dp_rate),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    #layers.Dropout(rate=dp_rate),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    #layers.Dropout(rate=dp_rate),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    #layers.Dropout(rate=dp_rate),\n",
    "    layers.Dense(1, activation='relu')\n",
    "])\n",
    "\n",
    "# Compile Keras model\n",
    "model.compile(\n",
    "    loss='mean_absolute_error',\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr))\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.057070e+05\n",
       "mean     6.887453e+03\n",
       "std      1.074045e+05\n",
       "min      0.000000e+00\n",
       "25%      1.150000e+03\n",
       "50%      2.950000e+03\n",
       "75%      7.200000e+03\n",
       "max      1.400050e+07\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.201400e+04\n",
       "mean     1.255307e+04\n",
       "std      7.173585e+05\n",
       "min      0.000000e+00\n",
       "25%      1.150000e+03\n",
       "50%      2.950000e+03\n",
       "75%      7.250000e+03\n",
       "max      1.000000e+08\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.price.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carskernel",
   "language": "python",
   "name": "carskernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
